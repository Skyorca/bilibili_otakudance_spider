 第四章 网页内容抽取Parser

part1: RE规则
http://www.runoob.com/python/python-reg-expressions.html
字符分为普通字符，特殊字符，特殊字符都需要转义才能匹配本来的对象
对一串需要匹配的对象，要找到哪些是固定的，哪些是可变的，固定的就用本身匹配（注意转义），可变的就写表达式。
返回一个列表，截取了多个匹配的子串
若要匹配一行文本开始处的文本，请在正则表达式的开始使用 ^ 字符。不要将 ^ 的这种用法与中括号表达式内的用法混淆。若要匹配一行文本的结束处的文本，请在正则表达式的结束处使用 $ 字符。
()圈出来子表达式，*,+,?都是针对子表达式而言的，如果没有则默认对象为前一个字符。
另外子表达式作为匹配返回的结果，前面非子表达式的作为过滤条件。
s1 = '<a href="http://www.bilibili.com/video/av3345678">picture</a>'
print(re.findall('href=\".*\"', s1)) 返回href="http://www.bilibili.com/video/av3345678"
print(re.findall('href=\"(.*)\"', s1)) 返回http://www.bilibili.com/video/av3345678域名本身，叫抽取外链，这里href=就是过滤条件


例子：一个抽取爬下的网页里所有http外链的例子
import requests
url = "http://www.bilibili.com"
r = requests.get(url)
r.encoding="utf8"
f = open("bili.html", "w+", encoding="utf8")
f.write(r.text)
f.close()
with open("bili.html", "r", encoding='utf8') as f:
    c = f.read() 读出来的是字符串
res = re.findall('href=\"http://(.*?)\"', c)
for idx in range(len(res)):
    print(res[idx].encode('utf8')) 依次打印列表中的每个字符串


贪婪模式：默认的，尽可能长的去找匹配子串（是最长的符合要求的）
非贪婪模式：?写在特殊字符中的限定符* + {n,m}后，表示匹配到最短的子串就停下
s = '<a href="https://www.baidu.com">Baidu</a><p>百度</p>'
re.findall(".*>(.*)<", s) 匹配的是“百度”，因为一开始的那个直接搜索到了“百度”之前
re.findall(".*?>(.*)<", s) 匹配的是'Baidu</a><p>百度'，因为搜索到Baidu之前那个>开始，因为子表达式
还是贪婪模式，所以一直匹配到百度后面那个<截止
re.findall(".*?>(.*?)<", s)[0] 结合前两个的非贪婪模式，正好搜索到Baidu,百度，和' '，返回列表第一个即可


re.sub(pattern, to_substring/function， string, times)
pattern里面可以设置过滤条件，即(?<=pattern1)pattern(?=pattern2)，前后两个作为过滤条件，不会被替换掉，只替换中间的.这个方法也可以用在re.findall()里面，但是子表达式的括号写法在sub里不能用。
即：
re.findall()的过滤可以用中间的（）子表达式，也可以前后用(?<=)(?=)设置逻辑.re.sub()的过滤只能用前后逻辑。
其他用法。注意sub是根据匹配去找所有符合规则的子串，每找到一个就返回一个search对象，之后进行一次替换(替换成子串或者调用函数)。
group是正则提取的分组。在pattern里面一个()就是一组。如果涉及到复杂的替换可能要用到传入函数，利用分组提取的办法来替换。
s = "AB12C3DEF4"
def f(matched):
        print(matched.group(1))
        print(matched.group(2))
re.sub('([A-Z]+)(\d+)', f, s)  #一共有两组，每次匹配时都会放到对应的组里
打印结果为：
AB
12
C
3
DEF
4
可以给分组起名字，用?P<groupname>的形式（?P<value>\d+）(?P<letter>[A-Z]+),之后用matched.group('value')方法提取



pattern = re.compile()方法生成正则模式对象pattern，相当于cache，提高速度
pattern.match() 从头匹配，或者指定开始下标
pattern.search() 找到第一个符合的
pattern.findall() 找到所有符合的
pattern.fullmatch()从头匹配，找整段符合要求的文本
match和search方法返回第一个符合的匹配对象。该对象可能被规则分成了几组，通过group方法提取。该对象的成员函数有：
    .group(digit/name)，即分组提取：某一组的值，默认为数字，也可以自己取名
    .start(digit/name) 某一组的起始下标
    .end(digit/name)   某一组的结束下标
    .span(digit/name)  某一组的跨度（start, end）
    .groupdict()       变成字典 digit/name:match_result






注： .匹配\n以外的全部字符，所以可以先用sub把.换成' '然后去匹配
英文单词的切分： [a-z]+
去掉某些字符保存其他内容的完整： [^...]+
\d表示一个数字，.代表任意一个字符，[]表示可以匹配任何一个出现在里面的字符（单个字符）
 ‘ ” 也需要转义（不然是字符串）



part2  DOM()选择器操作XPATH

XPATH:  HTML网页元素路径
DOM把XPATH解析成树， etree是轻量级的DOM，HTML是分块的，标签化的，所以每一个分块标签（body, div, p...）都是一个节点
，形成HTML树，在树上查找信息
节点：所有的标签都是节点

from lxml import etree
#首先建立XPATH解析对象，有两种方法
#1  从字符串建立
with open("xpath.html", 'r', encoding='utf8') as f:
    c = f.read()
s = re.sub('\n', ' ', c) #避免不必要的麻烦
html = etree.HTML(s)  #调用HTML类初始化，返回一个用HTML语言解析的XML Element
print(html) #<Element html at 0x111755c88> 这是根节点
#该类有xpath方法，返回符合要求对象的列表
ret1 = html.xpath('/html/body/div')
print(ret1) #[<Element div at 0x1041cbc08>, <Element div at 0x1041cbc48>]
ret2 = html.xpath('/html/body//div')
print(ret2) #[<Element div at 0x1056c0c48>, <Element div at 0x1056c0d48>, <Element div at 0x1056c0d88>, <Element div at 0x1056c0dc8>, <Element div at 0x1056c0e08>, <Element div at 0x1056c0e88>, <Element div at 0x1056c0c88>, <Element div at 0x1056c0ec8>, <Element div at 0x1056c0f08>]
ret3 = html.xpath('/html/body/div[1]/div')
ret3 = html.xpath('/html/body/div')[0].xpath('div')
这两个是等价的,都是取第几个块然后往下找子节点，注意第二种写法的子节点查找不能加//, .xpath('//div')会回到根节点查找整个树
print(ret3)
ret4 = html.xpath('//a/text()')#提取文本的方法
print(ret4[0].encode('utf8'))
#2 直接从文件建立
html = etree.parse(' xpath.html', etree.HTMLParser())

一次查找多个路径：
    .xpath('路径1 | 路径2')                     完整地搜索两条路径
    .xpath('//*[self::node1 or self::node2]') 在当前节点下搜索所有的node1 node2子孙

例子：抽取所有文本并还原为文本段,要求保持顺序不能变
假设文本保存在所有h1 h2节点和p节点内：
ret5 = html.xpath('...//*[self::h1 or self:: h2 or self::p]') #前面是什么路径可以自己选择，但是当前的路径必须是//*才能搜索所有的子孙
for ele in ret5:
    print(ele.text)


属性选择
滤出符合属性要求的节点，返回符合要求的XML Element对象的列表
.xpath('.../.[@attri = 'value']')        属性严格等于value
.xpath('.../.[contains(@attri, 'value')]') 属性包含value就行

属性逻辑运算：.xpath('.../.[@attri1 = 'value' or @attri2 = 'value']')  只有属性严格等于的都能选上
